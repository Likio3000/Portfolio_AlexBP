{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import logging\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "from contextlib import closing\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_webdriver(url):\n",
    "    try:\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.maximize_window()\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(10)  # 10 seconds\n",
    "\n",
    "        # Find the consent button on coinglass data terms\n",
    "        consent_button = driver.find_element(\n",
    "            By.XPATH, \"/html/body/div[2]/div[2]/div[1]/div[2]/div[2]/button[1]\"\n",
    "        )\n",
    "        consent_button.click()\n",
    "\n",
    "        # Scroll down the page\n",
    "        action = ActionChains(driver)\n",
    "        for _ in range(3):  # Scroll down 3 times\n",
    "            action.send_keys(Keys.PAGE_DOWN).perform()\n",
    "            time.sleep(1)  # Wait for 1 second between each scroll\n",
    "\n",
    "        return driver\n",
    "\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"Button of consent not found: {e}\")\n",
    "\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error initializing webdriver: {e}\")\n",
    "\n",
    "\n",
    "def scrape_data(driver, xpath_groups):\n",
    "    data = []\n",
    "    try:\n",
    "        for group_name, indices in xpath_groups.items():\n",
    "            element_labels = [\"All\", \"Long\", \"Short\"]\n",
    "            for index, label in zip(indices, element_labels):\n",
    "                xpath = f\"/html/body/div[1]/div[2]/div[1]/div[1]/div/div[1]/div[2]/div/div[1]/div/div[2]/div[{index}]/div\"\n",
    "                element = driver.find_element(By.XPATH, xpath)\n",
    "                value = element.get_attribute(\"aria-label\")\n",
    "                data.append({\"Grupo\": group_name, \"Elemento\": label, \"Valor\": value})\n",
    "        return pd.DataFrame(data)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during scraping: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def transform_data(df, current_timestamp):\n",
    "    try:\n",
    "        if \"Valor\" not in df.columns or df[\"Valor\"].isnull().any():\n",
    "            logging.error(\"Column 'Valor' is either missing or contains null values.\")\n",
    "            return None\n",
    "\n",
    "        # Check if the 'Valor' column needs transformation\n",
    "        if (\n",
    "            df[\"Valor\"].dtype != \"float64\"\n",
    "            or df[\"Valor\"].str.contains(\".\").any()\n",
    "            or df[\"Valor\"].str.contains(\",\").any()\n",
    "        ):\n",
    "            df[\"Valor\"] = (\n",
    "                df[\"Valor\"]\n",
    "                .str.replace(\".\", \"\", regex=False)\n",
    "                .str.replace(\",\", \".\", regex=False)\n",
    "                .astype(float)\n",
    "            )\n",
    "\n",
    "        new_data = []\n",
    "\n",
    "        for name, group in df.groupby(\"Grupo\"):\n",
    "            try:\n",
    "                all_liquidations = float(\n",
    "                    group.loc[group[\"Elemento\"] == \"All\", \"Valor\"].values[0]\n",
    "                )\n",
    "                long_liquidations = float(\n",
    "                    group.loc[group[\"Elemento\"] == \"Long\", \"Valor\"].values[0]\n",
    "                )\n",
    "                short_liquidations = float(\n",
    "                    group.loc[group[\"Elemento\"] == \"Short\", \"Valor\"].values[0]\n",
    "                )\n",
    "\n",
    "                if isinstance(long_liquidations, float) and isinstance(\n",
    "                    short_liquidations, float\n",
    "                ):\n",
    "                    ratio_long_short = long_liquidations / short_liquidations\n",
    "                    ratio_short_long = short_liquidations / long_liquidations\n",
    "                else:\n",
    "                    logging.error(\n",
    "                        f\"Invalid data types for long_liquidations or short_liquidations in group {name}. Skipping...\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                new_data.append(\n",
    "                    {\n",
    "                        \"Grupo\": name,\n",
    "                        \"Total_liquidations/1000\": all_liquidations / 1000,\n",
    "                        \"Long/Short Ratio\": ratio_long_short,\n",
    "                        \"Short/Long Ratio\": ratio_short_long,\n",
    "                        \"Timestamp\": current_timestamp,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            except (IndexError, ValueError) as e:\n",
    "                logging.error(\n",
    "                    f\"Data for group {name} is incomplete or in the wrong format. Skipping... Error: {e}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "        # Create a new DataFrame\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "\n",
    "        # Additional calculations and formatting\n",
    "        new_df[\"Long Liquidations\"] = new_df[\"Total_liquidations/1000\"] / (\n",
    "            1 + 1 / new_df[\"Long/Short Ratio\"]\n",
    "        )\n",
    "        new_df[\"Short Liquidations\"] = new_df[\"Total_liquidations/1000\"] / (\n",
    "            1 + new_df[\"Long/Short Ratio\"]\n",
    "        )\n",
    "\n",
    "        # Additional calculations for '%_Exchanges'\n",
    "        total_liquidations_TODO = new_df.loc[\n",
    "            new_df[\"Grupo\"] == \"TODO\", \"Total_liquidations/1000\"\n",
    "        ].values[0]\n",
    "        new_df[\"%_Exchanges\"] = (\n",
    "            new_df[\"Total_liquidations/1000\"] / total_liquidations_TODO * 100\n",
    "        )\n",
    "\n",
    "        # Formatting to strings should be the last step\n",
    "        new_df[\"Total_liquidations/1000\"] = new_df[\"Total_liquidations/1000\"].apply(\n",
    "            lambda x: \"{:,.0f}\".format(x)\n",
    "        )\n",
    "        new_df[\"Long/Short Ratio\"] = new_df[\"Long/Short Ratio\"].apply(\n",
    "            lambda x: \"{:.2f}\".format(x)\n",
    "        )\n",
    "        new_df[\"Short/Long Ratio\"] = new_df[\"Short/Long Ratio\"].apply(\n",
    "            lambda x: \"{:.2f}\".format(x)\n",
    "        )\n",
    "        new_df[\"Long Liquidations\"] = new_df[\"Long Liquidations\"].apply(\n",
    "            lambda x: \"{:,.0f}\".format(x)\n",
    "        )\n",
    "        new_df[\"Short Liquidations\"] = new_df[\"Short Liquidations\"].apply(\n",
    "            lambda x: \"{:,.0f}\".format(x)\n",
    "        )\n",
    "        new_df[\"%_Exchanges\"] = new_df[\"%_Exchanges\"].apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "        return new_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred during data transformation: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_sqlite_db(dataframe, table_name, conn):\n",
    "    try:\n",
    "        dataframe.to_sql(table_name, conn, if_exists=\"append\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while creating the SQLite table: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_scraper_liq():\n",
    "    url = \"https://www.coinglass.com/es/LiquidationData\"\n",
    "    xpath_groups = {\n",
    "        \"TODO\": list(range(8, 11)),\n",
    "        \"BINANCE\": list(range(14, 17)),\n",
    "        \"OKX\": list(range(20, 23)),\n",
    "        \"BYBIT\": list(range(26, 29)),\n",
    "        \"HUOBI\": list(range(32, 35)),\n",
    "    }\n",
    "    current_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    csv_file_path = \"processed_data/liquidations24h.csv\"\n",
    "    db_file_path = \"BTC_data.db\"\n",
    "    table_name = \"Liquidations24h\"\n",
    "\n",
    "    driver = initialize_webdriver(url)\n",
    "    if driver:\n",
    "        df = scrape_data(driver, xpath_groups)\n",
    "        driver.quit()\n",
    "        if df is not None:\n",
    "            print(df)\n",
    "            new_df = transform_data(df, current_timestamp)\n",
    "            print(\"new_df: \\n\", new_df)\n",
    "            new_df.to_csv(csv_file_path)\n",
    "            with closing(sqlite3.connect(db_file_path)) as conn:\n",
    "                create_sqlite_db(new_df, table_name, conn)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_scraper_liq()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
